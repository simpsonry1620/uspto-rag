{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a17cc5a-962d-4179-bb73-801433b83ea7",
   "metadata": {},
   "source": [
    "# USPTO MPEP RAG Example (Step 1 document processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e371f-5c09-4025-8b2b-ec71b7607696",
   "metadata": {},
   "source": [
    "First we need to verify that the raw PDFs exist locally, if not download and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b97cb9-98ff-475f-b983-b98e466897c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from openai import OpenAI\n",
    "\n",
    "# Define directories\n",
    "faiss_directory = '../data/scratch/vectordb/'\n",
    "# Directory to check for txt files exist\n",
    "txt_directory = '../data/scratch/txt/'\n",
    "\n",
    "# Check if the directory exists and contains any PDFs\n",
    "def check_txt_files_exist(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return False\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.lower().endswith('.txt'):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63047f1e-a73c-45b2-bead-027a0adc3941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text files already exist in the directory.\n"
     ]
    }
   ],
   "source": [
    "# Path to the script to run if PDFs are not found\n",
    "script_path = 'scrape_mpep_from_web.py'\n",
    "\n",
    "# Check if PDFs exist, if not run the script\n",
    "if check_txt_files_exist(txt_directory):\n",
    "    print(\"Raw text files already exist in the directory.\")\n",
    "else:\n",
    "    print(\"Raw text files not found. Running the download script...\")\n",
    "    result = subprocess.run(['python3', script_path], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"Script executed successfully.\")\n",
    "    else:\n",
    "        print(\"Error running the script.\")\n",
    "        print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d853428-42a0-452b-a44a-7c470e501cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded from ../data/scratch/vectordb/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Check if FAISS vector store exists\n",
    "if os.path.exists(faiss_directory) and os.listdir(faiss_directory):\n",
    "    # Load FAISS vector store\n",
    "    db = FAISS.load_local(faiss_directory, OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS index loaded from\", faiss_directory)\n",
    "else:\n",
    "    # Load documents\n",
    "    loader = DirectoryLoader(txt_directory, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    # Create FAISS vector store from documents\n",
    "    db = FAISS.from_documents(texts, embeddings)\n",
    "    \n",
    "    # Save the FAISS vector store\n",
    "    os.makedirs(faiss_directory, exist_ok=True)\n",
    "    db.save_local(faiss_directory)\n",
    "    print(\"FAISS index created and saved to\", faiss_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d841e55-53ca-471b-9568-0da4100b7771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='2203 Persons Who May Cite Prior Art or Written Statements [R-07.2015]\\nThe patent owner, or any member of the public, may submit prior art patents or printed publications and/or written statements and additional information to the Office. 35 U.S.C. 301 states that “[a]ny person at any time may cite to the Office....”\\n“Any person” may be a corporate or governmental entity as well as an individual. “Any person” includes patentees, licensees, reexamination requesters, real parties in interest to the patent owner or requester, persons without a real interest, and persons acting for real parties in interest without a need to identify the real party of interest. If a person citing prior art or written statements desires his or her identity to be kept confidential, such a person need not identify himself or herself.\\nPersons other than reexamination requesters who desire to remain confidential are therefore advised to not identify themselves anywhere in their papers. For reexamination requesters, the certification requirement of 37 CFR 1.510(b)(6), coupled with a party’s 37 CFR 11.18\\ncertification obligations when transacting business before the Office, are considered sufficient to ensure compliance with the inter partes review and post grant statutory estoppel requirements. A real party in interest that wishes to remain anonymous when filing a request for reexamination under 37 CFR 1.510 can do so by utilizing the services of a registered practitioner. In such an instance, the registered practitioner submitting a request for reexamination on behalf of the real party in interest would be certifying that the real party in interest was not estopped from filing the request.\\nConversely, an individual filing a request for reexamination under 37 CFR 1.510 on behalf of himself cannot remain anonymous, as he is required to sign the document that includes the 37 CFR 1.510(b)(6) certification. Confidential submissions should include proper proof of service as required by 37 CFR 1.248(b) that the patent owner has been sent a copy of the submission; otherwise the submission will not be entered into the patent file. Patent examiners should not, at their own initiative, create a submission under 35 U.S.C. 301 and place it in a patent file or forward it for placement in the patent file. Patent examiners are delegated by the Director with the responsibility of making decisions as to patentability. Any activity by examiners which would appear to indicate that patent claims are not patentable, outside of those cases pending before them, is inappropriate. [top]' metadata={'source': '../data/scratch/txt/s2203.txt'}\n"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "retrieved_docs = retriever.invoke(\"who can sumbit a patent?\")\n",
    "print(retrieved_docs[0])\n",
    "\n",
    "#https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/contextual_compression/#embeddingsfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f25055ab-2470-475f-96a6-edf770c496cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\"CustomChatOpenAI\" object has no field \"model\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://integrate.api.nvidia.com/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/mistral-large\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 47\u001b[0m custom_chat_openai \u001b[38;5;241m=\u001b[39m \u001b[43mCustomChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m messages \u001b[38;5;241m=\u001b[39m [BaseMessage(role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a limerick about the wonders of GPU computing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     50\u001b[0m chat_result \u001b[38;5;241m=\u001b[39m custom_chat_openai\u001b[38;5;241m.\u001b[39m_generate(messages)\n",
      "Cell \u001b[0;32mIn[32], line 14\u001b[0m, in \u001b[0;36mCustomChatOpenAI.__init__\u001b[0;34m(self, base_url, model, temperature, top_p, max_tokens)\u001b[0m\n\u001b[1;32m     12\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m     13\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_base \u001b[38;5;241m=\u001b[39m base_url\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature \u001b[38;5;241m=\u001b[39m temperature\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_p \u001b[38;5;241m=\u001b[39m top_p\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/main.py:357\u001b[0m, in \u001b[0;36mBaseModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m object_setattr(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mextra \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Extra\u001b[38;5;241m.\u001b[39mallow \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__fields__:\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m object has no field \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mallow_mutation \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39mfrozen:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is immutable and does not support item assignment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: \"CustomChatOpenAI\" object has no field \"model\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.schema import BaseMessage, ChatResult, ChatMessage\n",
    "from langchain.chat_models.base import BaseChatModel\n",
    "import openai\n",
    "\n",
    "class CustomChatOpenAI(BaseChatModel):\n",
    "    def __init__(self, base_url: str, model: str, temperature: float = 0.5, top_p: float = 1.0, max_tokens: int = 1024):\n",
    "        api_key = os.getenv('NVCF_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API key not found. Please set the environment variable 'NVCF_KEY'.\")\n",
    "        openai.api_key = api_key\n",
    "        openai.api_base = base_url\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def _call_openai(self, messages: List[Dict[str, Any]]) -> str:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=self.temperature,\n",
    "            top_p=self.top_p,\n",
    "            max_tokens=self.max_tokens,\n",
    "            stream=True\n",
    "        )\n",
    "        response = \"\"\n",
    "        for chunk in completion:\n",
    "            if chunk.choices[0].delta.get(\"content\"):\n",
    "                response += chunk.choices[0].delta[\"content\"]\n",
    "        return response\n",
    "\n",
    "    def _generate(self, messages: List[BaseMessage]) -> ChatResult:\n",
    "        formatted_messages = [{\"role\": msg.role, \"content\": msg.content} for msg in messages]\n",
    "        response = self._call_openai(formatted_messages)\n",
    "        chat_message = ChatMessage(role=\"assistant\", content=response)\n",
    "        return ChatResult(messages=[chat_message])\n",
    "\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom_openai\"\n",
    "\n",
    "# Usage example\n",
    "base_url = \"https://integrate.api.nvidia.com/v1\"\n",
    "model = \"mistralai/mistral-large\"\n",
    "\n",
    "custom_chat_openai = CustomChatOpenAI(base_url=base_url, model=model)\n",
    "\n",
    "messages = [BaseMessage(role=\"user\", content=\"Write a limerick about the wonders of GPU computing.\")]\n",
    "chat_result = custom_chat_openai._generate(messages)\n",
    "\n",
    "for message in chat_result.messages:\n",
    "    print(message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
